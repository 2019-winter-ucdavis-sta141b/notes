{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA 141B Lecture 8\n",
    "\n",
    "The class website is <https://github.com/2019-winter-ucdavis-sta141b/notes>\n",
    "\n",
    "### Announcements\n",
    "\n",
    "* Links to sample projects posted in Project Description\n",
    "* Submit project proposal as Markdown (`.md`) or Jupyter Notebook (`.ipynb`) in your project repo\n",
    "* Assignment 1 grades posted soon\n",
    "* Assignment 3 is posted\n",
    "\n",
    "### Topics\n",
    "\n",
    "* Query Strings\n",
    "* API Keys\n",
    "* Undocumented APIs\n",
    "\n",
    "### Datasets\n",
    "\n",
    "* [iTunes Search API](https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/)\n",
    "* [The Guardian API](https://open-platform.theguardian.com/)\n",
    "* [Yolo County Health Inspections](https://yoloeco.envisionconnect.com/)\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "* [__requests__ documentation](http://docs.python-requests.org/en/master/)\n",
    "* Python for Data Analysis, Ch. 6\n",
    "\n",
    "[PDSH]: https://jakevdp.github.io/PythonDataScienceHandbook/\n",
    "[ProGit]: https://git-scm.com/book/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Questions\n",
    "\n",
    "1. Approximately how many remixes are there of PSY's Gangnam Style?\n",
    "2. Did Clinton or Trump get more newspaper coverage in the days leading up to the 2016 U.S. presidential election?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Strings\n",
    "\n",
    "Most of the functions we use have parameters, and you can pass arguments for those parameters when you call a function.\n",
    "\n",
    "Endpoints in REST APIs work the same way, but the syntax is different. You can pass arguments by adding `?PARAMETER=ARGUMENT` to the end of the URL. Parameter and argument pairs are separated by `&`. This syntax is called a _query string_.\n",
    "\n",
    "For instance, Apple provides a web API for the iTunes store, with [documentation](https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/). We can use this to answer the example question about Gangnam Style.\n",
    "\n",
    "The search endpoint is `https://itunes.apple.com/search`, and the documentation lists several parameters. We can use __requests__ to build the query string automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "requests_cache.install_cache(\"mycache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.get(\"https://itunes.apple.com/search\", params = {\n",
    "    \"term\": \"Gangnam Style\",\n",
    "    \"country\": \"US\",\n",
    "    \"limit\": 200\n",
    "})\n",
    "response.raise_for_status()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every response has a `.url` attribute that shows the URL used for the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://itunes.apple.com/search?country=US&limit=200&term=Gangnam+Style'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = response.json()[\"results\"]\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "is_gangnam = results[\"trackName\"].str.contains(\"Gangnam Style\")\n",
    "\n",
    "results[is_gangnam][[\"trackName\", \"artistName\"]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Keys\n",
    "\n",
    "Many APIs use a _key_ or _token_ to identify the user.\n",
    "\n",
    "For instance, The Guardian, a British newspaper, provides a [web API](https://open-platform.theguardian.com/) to access their news articles. You need an API key to use their web APIs. You can get one for free [here](https://bonobo.capi.gutools.co.uk/register/developer).\n",
    "\n",
    "#### Storing API Keys\n",
    "\n",
    "Your API key is private and your responsibility. Treat it like a password. Keep it secret! **Don't commit it** in your git repo.\n",
    "\n",
    "In order to keep your API key separate from your code:\n",
    "1. Save the API key in a text file.\n",
    "2. Use Python to load the API key into a variable.\n",
    "\n",
    "Python's built-in `open()` function opens a file, and the `.readline()` method reads a line from a file. Often you'll see these used with `with`, which automatically closes the file at the end of the block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_key(keyfile):\n",
    "    with open(keyfile) as f:\n",
    "        return f.readline().strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my key\n"
     ]
    }
   ],
   "source": [
    "# Don't print out your actual API key\n",
    "print(read_key(\"keys/example\"))\n",
    "\n",
    "key = read_key(\"keys/guardian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can use the `key` variable anywhere you need the actual API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying The Guardian\n",
    "\n",
    "We've got our key, so let's use The Guardian API to answer our question about media coverage of Clinton and Trump.\n",
    "\n",
    "Let's start by trying to get all of the articles about one of the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(q, page = 1):\n",
    "    response = requests.get(\"https://content.guardianapis.com/search\", params = {\n",
    "        \"api-key\": key,\n",
    "        \"q\": q,\n",
    "        \"from-date\": \"2016-11-01\",\n",
    "        \"to-date\": \"2016-11-08\",\n",
    "        \"page-size\": 50,\n",
    "        \"page\": page\n",
    "    })\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_articles(q):\n",
    "    # Get the first page, and find out how many pages there are.\n",
    "    # NOTE: We could make this function clearer by renaming the `clinton` variable,\n",
    "    # since the function might be searching for something else.\n",
    "    clinton = get_articles(q)\n",
    "    pages = clinton[\"pages\"]\n",
    "\n",
    "    # Loop over remaining pages.\n",
    "    results = clinton[\"results\"]\n",
    "    for p in range(2, pages + 1):\n",
    "        results += get_articles(q, p)[\"results\"]\n",
    "        time.sleep(0.1)\n",
    "\n",
    "    # Convert the articles to data frame, and the date column to a date.\n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"webPublicationDate\"] = pd.to_datetime(df[\"webPublicationDate\"])\n",
    "    \n",
    "    # Get the day and day name, then count them.\n",
    "    date = df[\"webPublicationDate\"].dt\n",
    "    dates = pd.DataFrame({\"day\": date.day, \"day_name\": date.day_name()})\n",
    "    return dates.groupby([\"day\", \"day_name\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day  day_name \n",
      "1    Tuesday      28\n",
      "2    Wednesday    25\n",
      "3    Thursday     28\n",
      "4    Friday       31\n",
      "5    Saturday     19\n",
      "6    Sunday       32\n",
      "7    Monday       46\n",
      "8    Tuesday      49\n",
      "dtype: int64\n",
      "day  day_name \n",
      "1    Tuesday      40\n",
      "2    Wednesday    31\n",
      "3    Thursday     38\n",
      "4    Friday       45\n",
      "5    Saturday     26\n",
      "6    Sunday       44\n",
      "7    Monday       53\n",
      "8    Tuesday      55\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(get_all_articles(\"Clinton\"))\n",
    "print(get_all_articles(\"Trump\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some ways this analysis could be improved?\n",
    "\n",
    "* Check that articles about \"Trump\" and \"Clinton\" are actually about the two candidates. Some may be about other things -- the English word \"trump\", \"Bill Clinton\", etc...\n",
    "* Check whether the API searches article text or just article titles.\n",
    "* Use more sources, and use American newspapers (unless the goal was to analyze international news).\n",
    "* Make visualizations.\n",
    "* Use a larger time window.\n",
    "* Use other kinds of data (e.g., poll results) to look for relationships.\n",
    "\n",
    "Collecting and cleaning data takes a lot of very technical work, but it's only the first step in the analysis. When you finish data collection and cleaning, it can feel like you're finally done. Take a moment to congratulate yourself and step away from the data, so that when you come back you'll be ready to do a careful statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OAuth\n",
    "\n",
    "[OAuth](https://en.wikipedia.org/wiki/OAuth) is a way to give an application access to data on a website or web API.\n",
    "\n",
    "You might run into OAuth if you use a web API where the data is private. For instance, Twitter provides a [web API](https://developer.twitter.com/en/docs.html) for managing your personal Twitter account. If you want to access the API from a Python script, first you have to use OAuth to tell Twitter that the script has permission to use your data.\n",
    "\n",
    "OAuth can operate in several different ways. As always, check the documentation for the web API you want to use in order to find out what you need to do.\n",
    "\n",
    "The simplest case of OAuth requires scripts to have a key or token from the web API provider. This is very similar to using an API key.\n",
    "\n",
    "For more complicated cases, the **requests-ouathlib** package (documentation [here](https://requests-oauthlib.readthedocs.io/en/latest/)) may help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undocumented Web APIs\n",
    "\n",
    "Many websites use undocumented web APIs to get data. For example:\n",
    "\n",
    "* [University of California Compensation](https://ucannualwage.ucop.edu/wage/)\n",
    "* [Yolo County Health Inspections](https://yoloeco.envisionconnect.com/)\n",
    "\n",
    "You can identify these websites by looking at requests in your browser's developer tools. In Firefox or Chrome, you can open the developer tools with `ctrl-shift-i`.\n",
    "\n",
    "Requests to web APIs almost always return JSON or XML data. By examining the browser requests, you can work out the endpoints and parameters, allowing you to use the API.\n",
    "\n",
    "**CAUTION:** Web APIs that are undocumented are often undocumented for a reason. Using an undocumented API may make someone angry or get you into legal trouble! Government and quasi-government websites (like the examples above) are probably okay, as long as you cache and rate-limit your requests. For everything else, find for an alternative or get permission first."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
